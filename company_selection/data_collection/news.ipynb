{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T22:46:04.137012Z",
     "start_time": "2021-02-03T22:46:00.231668Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing all necessary libraries\n",
    "import newsfetch\n",
    "from newspaper import Article\n",
    "from newsfetch.google import google_search\n",
    "import newspaper\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These sites were chosen, for the time being, with little thought. The hope with this is to use these sites to get a sense for how the program runs. Sites can be added or removed with time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T22:52:11.040772Z",
     "start_time": "2021-02-03T22:52:11.036920Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating list of ESG sites\n",
    "sites = ['https://seekingalpha.com/market-news','https://www.investing.com/news/stock-market-news','https://www.marketwatch.com/','https://www.esgtoday.com/', 'https://www.ft.com/stream/e11a1e80-32df-4443-a483-5bd64245c9c4','https://esgclarity.com/','https://www.reuters.com/news/archive/esg-investing']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieving Daily Article Information "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What will this do:\n",
    "\n",
    "1. Go to each site in the sites list and grab all article urls on each \n",
    "2. Download, parse and perform nlp on each article \n",
    "3. Filter for articles that mention companys in question "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T22:53:11.374121Z",
     "start_time": "2021-02-03T22:52:39.715439Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Reading in pickled company list\n",
    "with open('data_files/public_company_list.data', 'rb') as filehandle:\n",
    "    companies = pickle.load(filehandle)\n",
    "\n",
    "# Creating list to hold relevant news articles\n",
    "news_data = []\n",
    "\n",
    "# Looping through sites\n",
    "for site in sites:\n",
    "    try:\n",
    "        # Building site\n",
    "        site = newspaper.build(site)\n",
    "        # Getting all article urls from built site\n",
    "        site_urls = site.article_urls()\n",
    "        # Looping through site article urls\n",
    "        for url in site_urls:\n",
    "            # Creating instance of article\n",
    "            article = Article(url)\n",
    "            # Downloading article\n",
    "            article.download()\n",
    "            # Parsing article\n",
    "            article.parse()\n",
    "            # Performing nlp prep on article\n",
    "            article.nlp()\n",
    "            # Creating variable for article text\n",
    "            text = article.text\n",
    "            # Filtering for relevant articles\n",
    "            for company, ticker in companies:\n",
    "                article_info = {}\n",
    "                if 'AAPL' in text:\n",
    "                    article_info['company'] = company \n",
    "                    article_info['url'] = url\n",
    "                    article_info['article_text'] = text\n",
    "                    news_data.append(article_info)\n",
    "    except:\n",
    "        print('Unsuccessful Site: {}'.format(site))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T22:53:17.312784Z",
     "start_time": "2021-02-03T22:53:17.305518Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T22:43:08.320211Z",
     "start_time": "2021-02-03T22:43:08.314649Z"
    }
   },
   "outputs": [],
   "source": [
    "check = pd.DataFrame(news_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T22:43:11.423421Z",
     "start_time": "2021-02-03T22:43:11.417727Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for company, ticker in companies: \n",
    "        # Filtering for articles that mention company\n",
    "        if 'company' in text:\n",
    "            # Creating new key value pair to specify company and url\n",
    "            daily_news_data.append({'company': company, \n",
    "                                    'url': url,\n",
    "                                    'article_text': text}, \n",
    "                                     ignore_index=True)\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T22:26:51.907399Z",
     "start_time": "2021-02-03T22:26:03.245646Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>url</th>\n",
       "      <th>article_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [company, url, article_text]\n",
       "Index: []"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking dataframe\n",
    "daily_news_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T22:27:24.013491Z",
     "start_time": "2021-02-03T22:27:23.994102Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>url</th>\n",
       "      <th>article_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zynex, Inc.</td>\n",
       "      <td>https://www.reuters.com/article/us-health-coro...</td>\n",
       "      <td>NEW YORK/LONDON/HONG KONG (Reuters Breakingvie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       company                                                url  \\\n",
       "0  Zynex, Inc.  https://www.reuters.com/article/us-health-coro...   \n",
       "\n",
       "                                        article_text  \n",
       "0  NEW YORK/LONDON/HONG KONG (Reuters Breakingvie...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_news_data.append({'company': company, \n",
    "                                    'url': url,\n",
    "                                    'article_text': text}, \n",
    "                                     ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Intialize list articles_info list\n",
    "# articles_info = []\n",
    "# for i in links:\n",
    "#     #Intialize dictionary\n",
    "#     article_dict = {}\n",
    "#     #Insert link \"i\" into the dictionary\n",
    "#     article_dict[\"link\"] = i\n",
    "#     #Pass link into Article() function\n",
    "#     art = Article(i)\n",
    "#     #Download contents of art object\n",
    "#     art.download()\n",
    "    \n",
    "#     #Try/except is included because not all articles can be parsed\n",
    "#     try:\n",
    "#         #If article can be successfully parsed then insert its text, title, publish_date, keywords\n",
    "#         #and summary into corresponding keys\n",
    "#         art.parse()\n",
    "#         article_dict[\"text\"] = art.text\n",
    "#         article_dict[\"title\"] = art.title\n",
    "#         article_dict[\"date\"] = art.publish_date\n",
    "#         art.nlp()\n",
    "#         article_dict[\"keywords\"] = art.keywords\n",
    "#         article_dict[\"summary\"] = art.summary\n",
    "#     except ArticleException:\n",
    "#         #If article cannot be parse then insert null values for the following keys:\n",
    "#         #\"text\", \"title\", \"date\", \"keywords\", and \"summary\"\n",
    "#         article_dict[\"text\"] = np.nan\n",
    "#         article_dict[\"title\"] = np.nan\n",
    "#         article_dict[\"date\"] = np.nan\n",
    "#         article_dict[\"keywords\"] = np.nan\n",
    "#         article_dict[\"summary\"] = np.nan\n",
    "        \n",
    "#     #Insert dictionary of article info into the articles_info list\n",
    "#     articles_info.append(article_dict)\n",
    "# #Pass the list of dictionaries into a pandas data frame\n",
    "# corpus = pd.DataFrame(articles_info)\n",
    "# #Print how long the process took\n",
    "# print(\"Script took {:.2f} seconds to complete\".format(time.time() - start))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
